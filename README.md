# Insurance Fraud Detection System ðŸ•µï¸

A machine learning system that detects insurance fraud by analyzing claim patterns, with a focus on identifying sophisticated fraud that traditional rule-based systems miss.

** Project Highlights:**
- 87% precision in fraud detection
- Potential savings of $2M+ annually
- Discovered counterintuitive fraud patterns (patient fraudsters, fake witnesses)
- End-to-end pipeline from raw data to deployable model

** Read the full story:** [[Medium Article - "I Built an Insurance Fraud Detector and Everything I Knew Was Wrong"](#)](https://medium.com/@logankhainga69/i-built-an-insurance-fraud-detector-and-everything-i-knew-was-wrong-b33ac823076b)

---

##  Project Overview

This project analyzes 1,000 insurance claims to build a predictive model that identifies fraudulent claims. Unlike traditional approaches that rely on obvious red flags, this system detects sophisticated fraud patterns through advanced feature engineering and machine learning.

### Key Findings

The analysis revealed surprising patterns that challenge conventional fraud detection assumptions:

| Expected Pattern | Actual Finding | Impact |
|-----------------|----------------|---------|
| Quick claims = fraud | Slow claims (>90 days) are 2x more likely to be fraud | Fraudsters are patient |
| No witnesses = fraud | Claims WITH witnesses show 26% fraud rate | Fraudsters bring fake witnesses |
| Avoid authorities = fraud | Authority-contacted claims show 26.5% fraud rate | Sophisticated fraudsters appear legitimate |
| Multiple red flags = fraud | Claim-to-premium ratio is the strongest single predictor | Financial patterns > behavioral patterns |

### Business Impact

**Risk Tiers:**
- **High Risk (Score > 0.7):** 87% precision, $63K avg claim â†’ Immediate investigation
- **Medium Risk (0.4-0.7):** 64% precision, $48K avg claim â†’ Enhanced documentation
- **Low Risk (< 0.4):** 12% precision, $34K avg claim â†’ Standard processing

**ROI Calculation:**
- Estimated fraud cases caught: 40/year
- Average fraudulent claim: $52,000
- Annual savings: **$2.08M**
- Investigation costs: $20,000
- **Net savings: $2.06M annually**


## ðŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- Jupyter Notebook (optional, for running notebooks)

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/yourusername/fraud-detection-decision-tree.git
cd insurance-fraud-detection
```

2. **Create a virtual environment (recommended):**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

### Quick Start

**Run the complete pipeline:**
```python
from src.data_processing import load_and_clean_data
from src.feature_engineering import engineer_features
from src.modeling import train_and_evaluate_models

# Load and clean data
df_clean = load_and_clean_data('data/raw/insurance_claims.csv')

# Engineer features
df_features = engineer_features(df_clean)

# Train models
results = train_and_evaluate_models(df_features)
print(results)
```

**Or explore step-by-step in Jupyter:**
```bash
jupyter notebook notebooks/
```

---

## ðŸ” Methodology

### 1. Data Cleaning

**Challenges:**
- 36% of records had "?" for property damage
- 34% missing police report information
- 18% unknown collision types
- Car make/model typos (Accura â†’ Acura, Suburu â†’ Subaru)

**Key Decision:** Treated "?" as a separate category rather than missing data, as analysis showed it correlated with fraud (31% fraud rate vs 21% for known values).

### 2. Feature Engineering

Created 15+ features across three categories:

Time-Based Features:

days_policy_to_incident: Days between policy start and claim
quick_claim: Binary flag for claims filed <90 days
very_quick_claim: Binary flag for claims filed <30 days

Financial Features:

claim_to_premium_ratio: Total claim Ã· Annual premium (strongest predictor)
extreme_claim_ratio: Binary flag for ratios >5x
high_value_claim: Binary flag for claims >$50k
no_witnesses: No witnesses present
no_police: No police report filed
no_authority: No authority contacted
multi_vehicle_no_witness: Multiple vehicles but no witnesses

Composite Features:

red_flag_score: Sum of suspicious indicators
injury_pct, property_pct, vehicle_pct: Claim composition breakdown

3. Model Selection
   Trained and compared three models:
ModelAccuracyPrecisionRecallF1-ScoreUse CaseLogistic Regression76%82%68%74%Baseline, interpretableRandom Forest81%87%72%79%Production candidateXGBoost83%89%74%81%Best performance
Why Precision Over Accuracy?

Baseline fraud rate: 24.7%
A "predict all legitimate" model would achieve 75.3% accuracy but catch zero fraud
Precision measures: When we flag fraud, how often are we right?
High precision = fewer wasted investigations

4. Feature Importance
Top 5 Predictive Features:

claim_to_premium_ratio (0.28 importance)
total_claim_amount (0.19 importance)
collision_type (0.14 importance)
days_policy_to_incident (0.12 importance)
policy_annual_premium (0.09 importance)
Surprising Non-Predictors:

Quick claim flags (inverse correlation)
Witness presence (inverse correlation)
Authority contact (inverse correlation)


Key Insights
Insight 1: Fraudsters Are Patient

Finding: Claims filed >90 days after policy start show 24.8% fraud rate
Comparison: Quick claims (<90 days) show only 12.5% fraud rate
Implication: Sophisticated fraudsters create realistic timelines to avoid suspicion

Insight 2: Financial Ratios Are King

Finding: Claims >5x annual premium show 26.8% fraud rate
Comparison: Normal ratios show 9.2% fraud rate
Lift: 2.9x more likely to be fraud
Why it matters: You can fake timelines and witnesses, but not the math

Insight 3: Witnesses Can Be Fake

Finding: Claims WITH witnesses show 26.2% fraud rate
Comparison: Claims WITHOUT witnesses show 20.1% fraud rate
Explanation: Fraudsters bring accomplices as fake witnesses

Insight 4: Rear-End Collisions Are Suspicious

Finding: Rear-end collisions show 31.2% fraud rate
Comparison: Unknown collisions show 9.0% fraud rate
Why: Easiest collision type to stage ("I stopped suddenly")

Insight 5: Calling Authorities Shows Confidence

Finding: Claims where authorities were contacted show 26.5% fraud rate
Comparison: No authority contacted shows 6.6% fraud rate
Interpretation: Sophisticated fraudsters call police because their staged accidents look legitimate

Business Metrics
Cost-Benefit Analysis:

True Positives: 36 fraud cases caught â†’ $1.87M saved
False Positives: 9 cases â†’ $4,500 investigation cost
False Negatives: 13 missed fraud cases â†’ $676K lost
Net Impact: $1.19M saved on 200-case test set

Scaling to Annual Volume (1,000 claims):

Net savings: $2.06M/year
